"""
Copyright Â© 2023 Howard Hughes Medical Institute, Authored by Carsen Stringer and Marius Pachitariu.
"""
import numpy as np
import matplotlib.pyplot as plt
from scipy.ndimage import gaussian_filter, gaussian_filter1d
from cellpose import io, transforms, models, metrics, denoise
from natsort import natsorted
from pathlib import Path
import torch
from torch import nn

# in same folder
try:
    import noise2self
    import noise2void
    import care
except Exception as e:
    print(e)
    print("noise2void / noise2self / care not installed, cannot run those comparisons")

io.logger_setup()

device = torch.device("cuda")

try:
    import segmentation_models_pytorch as smp

    class Transformer(nn.Module):

        def __init__(self, pretrained_model=None, encoder="mit_b5",
                     encoder_weights="imagenet", decoder="FPN"):
            super().__init__()
            net_fcn = smp.FPN if decoder == "FPN" else smp.MAnet
            self.net = net_fcn(
                encoder_name=encoder,
                encoder_weights=encoder_weights if pretrained_model is None else
                None,  # use `imagenet` pre-trained weights for encoder initialization
                in_channels=3,
                classes=3,
                activation=None)
            self.nout = 3
            self.mkldnn = False
            if pretrained_model is not None:
                state_dict = torch.load(pretrained_model)
                if list(state_dict.keys())[0][:7] == "module.":
                    from collections import OrderedDict
                    new_state_dict = OrderedDict()
                    for k, v in state_dict.items():
                        name = k[
                            7:]  # remove 'module.' of DataParallel/DistributedDataParallel
                        new_state_dict[name] = v
                    self.net.load_state_dict(new_state_dict)
                else:
                    self.load_state_dict(state_dict)

        def forward(self, X):
            X = torch.cat(
                (X, torch.zeros(
                    (X.shape[0], 1, X.shape[2], X.shape[3]), device=X.device)), dim=1)
            y = self.net(X)
            return y, torch.zeros((X.shape[0], 256), device=X.device)

        @property
        def device(self):
            return next(self.parameters()).device

except Exception as e:
    print(e)
    print("need to install segmentation_models_pytorch to run transformer")

model_names = {"poisson": "denoise", "blur": "deblur", "downsample": "upsample"}


def seg_eval_cp3(folder, noise_type="poisson"):
    """ need to download test_poisson.npy, test_blur.npy, test_downsample.npy
    (for cells and/or nuclei)
    
    (was computed with old flows, but results similar with new flows) """
    ctypes = ["cyto2", "nuclei"]
    for ctype in ctypes:
        folder_name = ctype
        diam_mean = 30 if ctype == "cyto2" else 17
        root = Path(folder) / f"images_{folder_name}/"

        ### cellpose enhance
        dat = np.load(root / "noisy_test" / f"test_{noise_type}.npy",
                      allow_pickle=True).item()
        test_noisy = dat["test_noisy"]
        masks_true = dat["masks_true"]
        diam_test = dat["diam_test"] if "diam_test" in dat else 30. * np.ones(
            len(test_noisy))

        istr = ["rec", "seg", "per", "perseg"]
        for k in range(len(istr)):
            model_name = model_names[noise_type]
            if istr[k] != "perseg":
                model_name += "_" + istr[k]
            model = denoise.DenoiseModel(gpu=True, nchan=1, diam_mean=diam_mean,
                                         model_type=f"{model_name}_{ctype}")
            imgs2 = model.eval([test_noisy[i][0] for i in range(len(test_noisy))],
                               diameter=diam_test, channel_axis=0)
            print(imgs2[0].shape)
            seg_model = models.CellposeModel(gpu=True, model_type=ctype)
            masks2, flows2, styles2 = seg_model.eval(imgs2, channels=[1, 0],
                                                     diameter=diam_test, channel_axis=0,
                                                     normalize=True)
            flows = [flow[0] for flow in flows2]

            ap, tp, fp, fn = metrics.average_precision(masks_true, masks2)
            if ctype == "cyto2":
                print(f"{istr[k]} AP@0.5 \t = {ap[:68,0].mean(axis=0):.3f}")
            else:
                print(f"{istr[k]} AP@0.5 \t = {ap[:,0].mean(axis=0):.3f}")

            dat[f"test_{istr[k]}"] = imgs2
            dat[f"masks_{istr[k]}"] = masks2
            dat[f"flows_{istr[k]}"] = flows

        #np.save(root / "noisy_test" / f"test_{noise_type}_cp3.npy", dat)

        if noise_type == "poisson":
            ### cellpose retrained
            dat = np.load(root / "noisy_test" / f"test_{noise_type}.npy",
                          allow_pickle=True).item()
            test_noisy = dat["test_noisy"]
            masks_true = dat["masks_true"]
            diam_test = dat["diam_test"] if "diam_test" in dat else 30. * np.ones(
                len(test_noisy))

            seg_model = models.CellposeModel(gpu=True, nchan=1,
                                             model_type=f"{ctype}_noisy")
            masks2 = seg_model.eval(test_noisy, channels=None, diameter=diam_test,
                                    normalize=False)[0]

            ap, tp, fp, fn = metrics.average_precision(masks_true, masks2)

            dat[f"masks_retrain"] = masks2

            #np.save(root / "noisy_test" / f"test_{noise_type}_cp_retrain.npy", dat)


def blind_denoising(folder):
    ctypes = ["cyto2", "nuclei"]
    for ctype in ctypes:
        root = Path(folder) / f"images_{ctype}/"

        ### noise2void
        imgs_n2v, masks_n2v = noise2void.train_per_image_synthetic(
            root, ctype=ctype, plot=0, save=False)
        dat = np.load(root / "noisy_test" / f"test_poisson.npy",
                      allow_pickle=True).item()
        masks_true = dat["masks_true"]
        print(len(masks_n2v), len(masks_true))
        ap = metrics.average_precision(masks_true, masks_n2v)[0]
        print(ap.mean(axis=0))

        ### noise2self
        imgs_n2s, masks_n2s = noise2self.train_per_image_synthetic(
            root, ctype=ctype, plot=0, save=True)
        dat = np.load(root / "noisy_test" / f"test_poisson.npy",
                      allow_pickle=True).item()
        masks_true = dat["masks_true"]
        print(len(masks_n2s), len(masks_true))
        ap = metrics.average_precision(masks_true, masks_n2s)[0]
        print(ap.mean(axis=0))


def real_examples(folder):
    """ download test_data from CARE and put in folder """

    cols = ["r", "g", "b"]

    dsets = ["Projection_Flywing", "Denoising_Tribolium"]

    thresholds = np.arange(0.5, 1.05, 0.05)
    flow_threshold = 0.4

    dat = {}
    for dset in dsets:
        root = Path(folder) / f"{dset}/test_data/"
        print(root)
        if dset == "Projection_Flywing":
            model_type = "denoise_cyto2"
            diam_mean = 30.
            cp_model_type = "cyto2"
        else:
            model_type = "denoise_nuclei"
            diam_mean = 17.
            cp_model_type = "nuclei"

        if dset == "Projection_Flywing":
            clean = [
                transforms.normalize99(io.imread(tif))
                for tif in natsorted(root.glob("proj_C2*.tif"))
            ]
            diam = 20.
            cellprob_threshold = -2.
        else:
            imgs = [io.imread(tif) for tif in natsorted(root.glob("*.tif"))]
            dz = 8
            clean = [
                transforms.normalize99(img[-1][img.shape[1] // 2 -
                                               dz:img.shape[1] // 2 + dz].max(axis=0))
                for img in imgs
            ]
            diam = 12.
            cellprob_threshold = 0.

        print(diam_mean)
        model = denoise.DenoiseModel(gpu=True, nchan=1, diam_mean=diam_mean,
                                     model_type=model_type)
        seg_model = models.CellposeModel(gpu=True, model_type=cp_model_type,
                                         diam_mean=diam_mean)
        masks_clean = seg_model.eval(clean, diameter=diam,
                                     cellprob_threshold=cellprob_threshold,
                                     flow_threshold=flow_threshold)[0]
        dat["clean"] = clean
        dat["masks_clean"] = masks_clean
        dat["noisy"] = []
        dat["ap_noisy"] = []
        dat["masks_noisy"] = []
        dat["denoised"] = []
        dat["masks_denoised"] = []
        dat["ap_denoised"] = []

        plt.figure(figsize=(4, 4))
        for nl in range(3):
            if dset == "Projection_Flywing":
                nstr = f"proj_C{nl+(nl>1)}"
                print(nstr)
                noisy = [
                    transforms.normalize99(io.imread(tif))
                    for tif in natsorted(root.glob(f"{nstr}*.tif"))
                ]
            elif dset == "Denoising_Tribolium":
                noisy = [transforms.normalize99(img[nl][img.shape[1] // 2 - dz:img.shape[1] // 2 + dz].max(axis=0)) for img in imgs]  #.max(axis=0)
            else:
                noisy = [
                    io.imread(tif)
                    for tif in natsorted((root / f"condition_{nl+1}").glob("*.tif"))
                ]
                noisy = [
                    transforms.normalize99(img[img.shape[0] // 4:img.shape[0] // 4 +
                                               dz].max(axis=0)) for img in noisy
                ]

            denoised = model.eval(noisy, channels=None, diameter=diam)
            masks_denoised = seg_model.eval(
                denoised,
                diameter=diam,
                cellprob_threshold=cellprob_threshold,
                flow_threshold=flow_threshold,
            )[0]
            masks_noisy = seg_model.eval(noisy, diameter=diam,
                                         cellprob_threshold=cellprob_threshold,
                                         flow_threshold=flow_threshold)[0]

            thresholds = np.arange(0.5, 1.05, 0.05)
            ap_noisy = metrics.average_precision(masks_clean, masks_noisy,
                                                 threshold=thresholds)[0]
            ap_denoised = metrics.average_precision(masks_clean, masks_denoised,
                                                    threshold=thresholds)[0]

            plt.plot(thresholds, ap_denoised.mean(axis=0), ls="-", color=cols[nl])
            plt.plot(thresholds, ap_noisy.mean(axis=0), ls="--", color=cols[nl])

            dat["noisy"].append(noisy)
            dat["masks_noisy"].append(masks_noisy)
            dat["ap_noisy"].append(ap_noisy)

            dat["denoised"].append(denoised)
            dat["masks_denoised"].append(masks_denoised)
            dat["ap_denoised"].append(ap_denoised)

        plt.show()
        np.save(root / "cp_masks.npy", dat)

        noisy = []
        for nl in range(3):
            noisy.extend(dat["noisy"][nl])
        print(len(noisy))

        imgs_n2s, masks_n2s = [], []
        for i in range(len(noisy)):
            pred_val = noise2self.train_per_image(noisy[i][np.newaxis,
                                                           ...].astype("float32"))
            masks = seg_model.eval(pred_val, diameter=diam,
                                   cellprob_threshold=cellprob_threshold,
                                   channels=[1, 0], channel_axis=0, normalize=True)[0]
            imgs_n2s.append(pred_val)
            masks_n2s.append(masks)

            print(f">>> IMAGE {i}, n_masks = {masks.max()}")

        ap_n2s = [
            metrics.average_precision(
                masks_clean,
                masks_n2s[nl * len(masks_clean):(nl + 1) * len(masks_clean)],
                threshold=thresholds)[0] for nl in range(3)
        ]
        dat2 = {}
        dat2["denoised_n2s"] = imgs_n2s
        dat2["masks_n2s"] = masks_n2s
        dat2["noisy"] = noisy
        dat2["masks_clean"] = masks_clean
        dat2["ap_n2s"] = ap_n2s
        np.save(root / "n2s_masks.npy", dat2)

        imgs_n2v, masks_n2v = [], []
        for i in range(len(noisy)):
            pred_val = noise2void.train_per_image(noisy[i])
            masks = seg_model.eval(pred_val, diameter=diam,
                                   cellprob_threshold=cellprob_threshold,
                                   channels=[1, 0], channel_axis=0, normalize=True)[0]
            imgs_n2v.append(pred_val)
            masks_n2v.append(masks)

            print(f">>> IMAGE {i}, n_masks = {masks.max()}")

        ap_n2v = [
            metrics.average_precision(
                masks_clean,
                masks_n2v[nl * len(masks_clean):(nl + 1) * len(masks_clean)],
                threshold=thresholds)[0] for nl in range(3)
        ]
        dat2 = {}
        dat2["denoised_n2v"] = imgs_n2v
        dat2["masks_n2v"] = masks_n2v
        dat2["noisy"] = noisy
        dat2["masks_clean"] = masks_clean
        dat2["ap_n2v"] = ap_n2v
        np.save(root / "n2v_masks.npy", dat2)


def specialist_training(root):
    """ root is path to specialist images (first 89 images of cyto2 and first 11 test images) """

    # make patches for training CARE, noise2self and noise2void
    care.CIL_dataset(root)

    # train/test CARE
    care.train_test_specialist(root)

    # train/test noise2self
    imgs, masks_n2s, ap = noise2self.train_test_specialist(root, n_epochs=50, lr=5e-4,
                                                           test=True)

    # train/test noise2void
    noise2void.train_test_specialist(root, n_epochs=100, lr=4e-4, test=True)


def seg_eval_oneclick(folder):
    noise_types = ["poisson", "blur", "downsample"]
    ctypes = ["cyto2", "nuclei"]
    for c, ctype in enumerate(ctypes):
        folder_name = ctype
        diam_mean = 30.
        root = Path(f"/media/carsen/ssd4/datasets_cellpose/images_{folder_name}/")
        print(ctype)
        for n, noise_type in enumerate(noise_types):
            print(noise_type)
            ### cellpose enhance
            dat = np.load(root / "noisy_test" / f"test_{noise_type}.npy",
                          allow_pickle=True).item()
            test_noisy = dat["test_noisy"]
            masks_true = dat["masks_true"]
            diam_test = dat["diam_test"] if "diam_test" in dat else 30. * np.ones(
                len(test_noisy))

            model = denoise.DenoiseModel(gpu=True, nchan=1, diam_mean=diam_mean,
                                         model_type=model_names[noise_type] + "_cyto3",
                                         device=torch.device("cuda"))
            imgs2 = model.eval([test_noisy[i][0] for i in range(len(test_noisy))],
                               diameter=diam_test, channel_axis=0)

            seg_model = models.CellposeModel(gpu=True, model_type=ctype,
                                             device=torch.device("cuda"))
            masks2, flows2, styles2 = seg_model.eval(imgs2, channels=[1, 0],
                                                     diameter=diam_test, channel_axis=0,
                                                     normalize=True)
            istr = "generalist"
            ap, tp, fp, fn = metrics.average_precision(masks_true, masks2)
            if ctype == "cyto2":
                print(f"{istr} AP@0.5 \t = {ap[:68,0].mean(axis=0):.3f}")
            else:
                print(f"{istr} AP@0.5 \t = {ap[:,0].mean(axis=0):.3f}")

            dat[f"test_{istr}"] = imgs2
            dat[f"masks_{istr}"] = masks2

            np.save(root / "noisy_test" / f"test_{noise_type}_generalist_cp3.npy", dat)


def cyto3_comparisons(folder):
    """  diameters computed from generalist model cyto3
    will need segmentation_models_pytorch to run transformer """
    root = Path(folder)
    folders = [
        "cyto2", "nuclei", "tissuenet", "livecell", "yeast_BF", "yeast_PhC",
        "bact_phase", "bact_fluor", "deepbacs"
    ]

    net_types = ["generalist", "specialist", "transformer"]
    for net_type in net_types:
        if net_type == "generalist":
            seg_model = models.Cellpose(gpu=True, model_type="cyto3")
        elif net_type == "transformer":
            seg_model = models.CellposeModel(gpu=True, pretrained_model=None)
            pretrained_model = "/home/carsen/.cellpose/models/transformer_cp3"
            seg_model.net = Transformer(pretrained_model=pretrained_model,
                                        decoder="MAnet").to(device)
        for f in folders:
            if net_type == "specialist":
                seg_model = models.CellposeModel(gpu=True, model_type=f"{f}_cp3")

            root = Path(folder) / f"images_{f}"
            channels = [1, 2] if f == "tissuenet" or f == "cyto2" else [1, 0]
            tifs = (root / "test").glob("*.tif")
            tifs = [tif for tif in tifs]
            tifs = [
                tif for tif in tifs
                if "_masks" not in str(tif) and "_flows" not in str(tif)
            ]
            if net_type != "generalist":
                d = np.load(
                    f"/media/carsen/ssd4/datasets_cellpose/{f}_generalist_masks.npy",
                    allow_pickle=True).item()
                diams = d["diams"]
            else:
                diams = 0

            imgs = [io.imread(tif) for tif in tifs]
            flows = [io.imread(str(tif)[:-4] + "_flows.tif") for tif in tifs]
            masks = [flow[0].astype("uint16") for flow in flows]

            if f == "cyto2":
                imgs = imgs[:68]
                masks = masks[:68]

            dat = {}
            dat["imgs"] = imgs
            dat["masks"] = masks
            dat["files"] = tifs
            out = seg_model.eval(imgs, diameter=diams, channels=channels,
                                 tile_overlap=0.5, flow_threshold=0.4, augment=True,
                                 bsize=224, niter=2000 if f == "bact_phase" else None)
            if len(out) == 3:
                masks_pred, flows_pred, styles = out
            else:
                masks_pred, flows_pred, styles, diams = out
            ap, tp, fp, fn = metrics.average_precision(
                masks, masks_pred, threshold=np.arange(0.5, 1.05, 0.05))
            print(ap.mean(axis=0))
            dat["masks_pred"] = masks_pred
            dat["performance"] = [ap, tp, fp, fn]
            dat["diams"] = diams

            #p.save(f"/media/carsen/ssd4/datasets_cellpose/{f}_{net_type}_masks.npy", dat)


if __name__ == '__main__':
    # folder with folders images_cyto2 and images_nuclei for those datasets
    folder = "/media/carsen/ssd4/datasets_cellpose/"

    # https://publications.mpi-cbg.de/publications-sites/7207/
    folder2 = "/media/carsen/ssd4/denoising/"  # download CARE datasets here

    ### run cyto2/nuclei denoising analyses
    seg_eval_cp3(folder, noise_type="poisson")

    ### train cyto2/nuclei per image models with noise2void and noise2self
    blind_denoising(folder)

    ### real data: run cyto2/nuclei models + train cyto2/nuclei per image models with noise2void and noise2self
    real_examples(folder2)

    ### specialist denoising -- train CARE, noise2void + noise2self
    specialist_training(Path(folder) / "images_cyto2")

    ### run cyto2/nuclei deblurring analyses
    seg_eval_cp3(folder, noise_type="blur")

    ### run cyto2/nuclei upsampling analyses
    seg_eval_cp3(folder, noise_type="downsample")

    ### oneclick cyto2/nuclei performance
    seg_eval_oneclick(folder)

    ### run supergeneralist segmentation models analyses
    cyto3_comparisons(folder)
